// Gaussian mixture model class
// Hand writing recognition Januari project, MSc AI, University of Amsterdam
// Thijs Kooi, 2011

#include "gmm.h"

//To do:
// Add EM to train priors
// Work on elegant initialisation of the model for 1 or more mixture components
// optimise, work on arrays rather than vectors

double PI = 4.0*atan(1.0);

// int main()
// {
// 	GMM testMOG(1);
// 	
// 	double a[4] = {3,4,7,1};
// 	double b[4] = {1,4,2,3};
// 	vector<double> av = testMOG.arrayToVector(a,4);
// 	vector<double> bv = testMOG.arrayToVector(b,4);
// 	
// 	cout << "AV" << endl;
// 	testMOG.printMatrix(av);
// 	cout << "BV" << endl;
// 	testMOG.printMatrix(bv);
// 	
// 	testMOG.testOuterProduct(av, bv);
// }

//Constructors and intialisation functions
GMM::GMM(int d) { mixture_components = 1; data_dimension = d; initialiseParameters(); }
GMM::GMM(int d, int n) { mixture_components = n; data_dimension = d; initialiseParameters(); }
GMM::GMM(vector<double> mu,vector<vector<double> > sigma) 
{ 
	mixture_components = 1;
	priors.push_back(1.0);
	if(mu.size() != sigma.size())
	{
		cout << "Error: size of mean and covariance do not agree." << endl;
		return;
	}
	data_dimension = mu.size();
	means.push_back(mu);
	covariances.push_back(sigma);
}

//Initialise mixture components with equal priors, zero mean and unit variance
void GMM::initialiseParameters()
{
	vector<double> zero_mean;
	vector<vector<double> > unit_covariance;
	
	zero_mean.assign(data_dimension,0.0);
	unit_covariance.assign(data_dimension,zero_mean);
	
	for(size_t d1 = 0; d1 < data_dimension; ++d1)
		for(size_t d2 = 0; d2 < data_dimension; ++d2)
			if(d1==d2)
				unit_covariance[d1][d2]=1.0;
	
	for(size_t i = 0; i < mixture_components; ++i)
	{
		priors.push_back(1.0/mixture_components);
		means.push_back(zero_mean);
		covariances.push_back(unit_covariance);
	}
}
//end constructors and initialisation functions

// void GMM::EM(vector<vector<double> > data)
// {
// 	double current_likelihood = likelihood();
// 	double previous_likelihood = 0.0;
// 	
// 	while(current_likelihood - previous_likelihood > 0.0001)
// 	{
// 		posterior_probabilities = estimatePosterior(data);
// 		maximiseMean(posterior_probabilities,data);
// 		maximiseCovariance(posterior_probabilities,data);
// 		maximisePriors(posterior_probabilites,data);
// 	}
// 	
// }
// 
// double** GMM::estimatePosterior(vector<vector<double> > data)
// {
// 	for(size_t t = 0; t < data.size(); ++t)
// 	{
// 		posterior_probabilities[t] = new double[data[t].size()];
// 		for(size_t k = 0; k < mixture_components; ++k)
// 			posterior_probabilities[t][k] = posteriorProbability(data[t],k);
// 	}
// }
// 
// //Needs optimising (product/sum)
// double GMM::likelihood(vector<vector<double> > x)
// {
// 	double likelihood = 1.0;
// 	double point_prob;
// 	
// 	for(size_t i = 0; i < x.size(); ++i)
// 	{
// 		point_prob = 0.0;
// 		for(size_t k = 0; k < mixture_components; ++k)
// 			point_prob+=prior_probabilities[k]*gaussianProb(x,means[k],covariances[k]);
// 		likelihood*=point_prob;
// 	}
// 	
// 	return likelihood;
// }
// 
// //Posterior probability of a data point x being generated by mixture component
// void GMM::posteriorProbability(vector<double> x, int component)
// {
// 	double numerator = priors[component]*pow(determinant(covariances[component]),0.5)*exp(-0.5*mahalanobisDistance(x,means[component],covariances[component]));
// 	double denominator = 0.0;
// 	
// 	for(size_t k = 0; k < mixture_components; ++k)
// 		denominator+=priors[k]*pow(determinant(covariances[k]),0.5)*exp(-0.5*mahalanobisDistance(x,means[k],covariances[k]));
// 	
// 	return numerator/denominator;
// }
// 
// void GMM::maximisePriors(double **posteriors, vector<double> x)
// {
// 	double numerator = 0.0;
// 	double denominator = 0.0;
// 	
// 	for(size_t k = 0; k < mixture_components; ++k)
// 		
// }
// 
// void GMM::maximiseMean(double **posteriors, vector<vector<double> > data)
// {
// 	double numerator;
// 	double denominator;
// 	vector<double> new_mean;
// 	
// 	for(size_t k = 0; k < mixture_components; ++k)
// 	{
// 		denominator = 0.0;
// 		new_mean.clear();
// 		for(size_t t = 0; t < data.size(); ++t)
// 			denominator+=posteriors[t][d];
// 			
// 		numerator = 0.0;
// 		for(size_t t = 0; t < data.size(); ++t)
// 			for(size_t d = 0; d < data[t].size(); ++d)
// 			{
// 				numerator+=posteriors[t][k]*data[t][d];
// 				means.push_back(numerator/denominator);
// 			}
// 			
// 		means[k] = new_mean;
// 	}		
// }
// 
// void GMM::maximiseCovariance(double **posteriors, vector<double> x)
// {
// 	double numerator = 0.0;
// 	double denominator = 0.0;
// 	
// 	for(size_t k = 0; k < mixture_components; ++k)
// }

double GMM::gausianProb(vector<double> x, vector<double> mean, vector<vector<double> > covariance)
{
	double normalisation_constant = 1.0/( pow((2.0*PI),x.size()/2.0) * pow(determinant(covariance),0.5) );
	double exponent = -0.5*mahalanobisDistance(x,mean,covariance);
	
	return normalisation_constant*exp(exponent);
}

double GMM::gmmProb(vector<double> x)
{
	double product = 0.0;
	for(size_t k = 0; k < mixture_components; ++k)
		product+=priors[k]*gmmProb(x,k);
	return product;
}

double GMM::gmmProb(vector<double> x, int component_number)
{
	double normalisation_constant = 1.0/( pow((2.0*PI),data_dimension/2.0) * pow(determinant(covariances[component_number]),0.5) );
	double exponent = -0.5*mahalanobisDistance(x,means[component_number],covariances[component_number]);
	
	return normalisation_constant*exp(exponent);
}

//Math functions
double GMM::mahalanobisDistance(vector<double> x,vector<double> mean,vector<vector<double> > covariance)
{
	vector<double> difference;
	for(size_t d = 0; d < data_dimension; ++d)
		difference.push_back(x[d]-mean[d]);
	
	vector<vector<double> > inverse_covariance = inverse(covariance);
	
	vector<double> distance ;
	for(size_t d = 0; d < data_dimension; ++d)
		distance.push_back(innerProduct(difference,inverse_covariance[d]));
	
	return innerProduct(distance,difference);
}

vector<double> GMM::vectorAdd(vector<double> a, vector<double> b)
{
	for(size_t d = 0; d < a.size(); ++d)
		a[d]+=b[d];
	return a;
}

vector<vector<double> > GMM::vectorAdd(vector<vector<double> > A, vector<vector<double> > B)
{
	for(size_t d1 = 0; d1 < A.size(); ++d1)
		for(size_t d2 = 0; d2 < A[d1].size(); ++d2)
			A[d1][d2]+=B[d1][d2];
	return A;
}

vector<double> GMM::vectorSubtract(vector<double> a, vector<double> b)
{
	for(size_t d = 0; d < a.size(); ++d)
		a[d]-=b[d];
	return a;
}

//Multiplies vector a with scalar \alpha
vector<double> GMM::vectorScalarProduct(vector<double> a, double alpha)
{
	for(size_t d = 0; d < a.size(); ++d)
		a[d]*=alpha;
	return a;
}

vector<vector<double> > GMM::vectorScalarProduct(vector<vector<double> > A, double alpha)
{
	for(size_t d1 = 0; d1 < A.size(); ++d1)
		for(size_t d2 = 0; d2 < A[d1].size(); ++d2)
			A[d1][d2]*=alpha;
	return A;
}

//a^{T}b
double GMM::innerProduct(vector<double> a, vector<double> b)
{
	double sum = 0.0;
	for(size_t d = 0; d < a.size(); ++d)
		sum+=a[d]*b[d];
	return sum;
}

//ab^{T}
vector<vector<double> > GMM::outerProduct(vector<double> a, vector<double> b)
{
	vector<vector<double> > out;
	vector<double> row;
	
	for(size_t i = 0; i < a.size(); ++i)
	{
		row.clear();
		for(size_t j = 0; j < b.size(); ++j)
			row.push_back(a[i]*b[j]);
		out.push_back(row);
	}
	
	return out;
}

double GMM::determinant(vector<vector<double> > A)
{
	if(A.size() == 1)
		return A[0][0];
	else if(A.size() == 2)
		return A[0][0]*A[1][1] - A[1][0]*A[0][1];
	else
	{
		double det = 0.0;
		for(size_t d = 0; d < A.size(); ++d)
		{
			if(d%2 == 0)
				det+=A[0][d]*determinant(getMinor(A,0,d));
			else
				det-=A[0][d]*determinant(getMinor(A,0,d));
		}
		return det;
	}	
}

vector<vector<double> > GMM::getMinor(vector<vector<double> > mat, int m, int n)
{
	mat.erase(mat.begin()+m);
	for(size_t j = 0; j < mat.size(); ++j)
		mat[j].erase(mat[j].begin()+n);
	
	return mat;
}

vector<vector<double> > GMM::inverse(vector<vector<double> > A)
{
	double detA = determinant(A);
	if(detA == 0.0)//Matrix is singular
	{
		cout << "Matrix is singular, can not take inverse!" << endl;
		return A;
	}
	else
	{
		vector<vector<double> > AInverse;
		vector<double> row;
		for(size_t m = 0; m < A.size(); ++m)
		{
			row.clear();
			for(size_t n = 0; n < A.size(); ++n)
			{
				if((m+n)%2 == 0)
					row.push_back( (1.0/detA)*determinant(getMinor(A,m,n)));
				else
					row.push_back( (-1.0/detA)*determinant(getMinor(A,m,n)));
			}
			AInverse.push_back(row);
		}
		
		return transpose(AInverse);
	}
}

vector<vector<double> > GMM::transpose(vector<vector<double> > A)
{
	vector<vector<double> > Atranspose;
	vector<double> row;
	
	for(size_t m = 0; m < A.size(); ++m)
	{
		row.clear();
		for(size_t n = 0; n < A.size(); ++n)
			row.push_back(0.0);
		Atranspose.push_back(row);
	}
	for(size_t m = 0; m < A.size(); ++m)
		for(size_t n = 0; n < A.size(); ++n)
			Atranspose[m][n] = A[n][m];
		
	return Atranspose;
	
}
//End math functions

//Getters and setters
int GMM::getMixtureComponents() { return mixture_components; }
void GMM::setMixtureComponents(int N) { mixture_components =  N; }

int GMM::getDimension() { return data_dimension; }
void GMM::setDimension(int d) { data_dimension = d; }

int GMM::getPrior(int component_number) { return priors[component_number]; }
void GMM::setPrior(int component_number,double probability) { priors[component_number] = probability; }

vector<double> GMM::getMean(int component_number) { return means[component_number]; }
void GMM::setMean(int component_number,vector<double> mean) { means[component_number] = mean; }
void GMM::setMean(vector<double> mean) { means[0] = mean; }

vector<vector<double> > GMM::getCovariance(int component_number) { return covariances[component_number]; } 
void GMM::setCovariance(int component_number, vector<vector<double> > covariance) { covariances[component_number] = covariance; }
void GMM::setCovariance(vector<vector<double> > covariance) { covariances[0] = covariance; }
//End getters and setters

//Print functions
void GMM::printPrior(int component_number)
{
	cout << "Prior for component " << component_number << endl;
	cout << priors[component_number] << endl;
}
void GMM::printMean(int component_number)
{
	cout << "Mean of component " << component_number << endl;
	printMatrix(means[component_number]);
}
void GMM::printCovariance(int component_number)
{
	cout << "Covariance of component " << component_number << endl;
	printMatrix(covariances[component_number]);
}
void GMM::printParameters(int component_number)
{
	cout << "Parameters for component " << component_number << endl;
	cout << "Prior: " << priors[component_number] << endl;
	cout << "Means: " << endl;
	printMatrix(means[component_number]);
	cout << "Covariance: " << endl;
	printMatrix(covariances[component_number]);
}
//end print functions

// Testing and debugging
vector<double> GMM::arrayToVector(double *array, int array_size)
{
	vector<double> output;
	output.reserve(array_size);
	
	for(size_t i = 0; i < array_size; ++i)
		output.push_back(array[i]);
	
	return output;
}

void GMM::printMatrix(vector<vector<double> > A)
{
	for(size_t i = 0; i < A.size(); ++i)
	{
		for(size_t j = 0; j < A[i].size(); ++j)
			cout << A[i][j] << " ";
		cout << endl;
	}
}
void GMM::printMatrix(vector<double> b)
{
	for(size_t i = 0; i < b.size(); ++i)
		cout << b[i] << " ";
	cout << endl;
}